{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-diesel",
   "metadata": {},
   "source": [
    "## SVM\n",
    "    letter data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spare-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set_style('white')  # plot formatting\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-group",
   "metadata": {},
   "source": [
    "## SVM\n",
    "    letter dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "killing-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import letter data set\n",
    "#letter1 for the problem with 'O' as the postive class rest as negative\n",
    "#letter2, for the problem with A-M as positive and N-Z as negative\n",
    "letter = pd.read_csv('letter-recognition.data')\n",
    "\n",
    "letter_ = letter.replace('O', +1) \n",
    "letter1 = letter_.replace(to_replace = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', \n",
    "                                           'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'], value = -1)\n",
    "letter_Y = letter.replace (to_replace = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'], value = +1) \n",
    "letter2 = letter_Y.replace(to_replace = ['N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'], value = -1)\n",
    "\n",
    "X_1 = letter1\n",
    "Y_1 = X_1[['T']]\n",
    "X_1 = X_1.iloc[:, 1:]\n",
    "\n",
    "X_2 = letter2\n",
    "Y_2 = X_2[['T']]\n",
    "X_2 = X_2.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}]\n",
      "[0.9934000000000001, 0.9981702494076231, 0.9934000000000001, 0.9932000000000001, 0.9985978634751941, 0.9932000000000001, 0.9907999999999999, 0.9967267022805366, 0.9907999999999999, 0.9932000000000001, 0.9971481093495094, 0.9932000000000001, 0.9934000000000001, 0.9961189418279073, 0.9934000000000001]\n"
     ]
    }
   ],
   "source": [
    "optimal_hyperparameters_1 = []\n",
    "mean_scores_1 = []\n",
    "variance_1 = []\n",
    "\n",
    "for i in range (5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, train_size = 5000)\n",
    "    \n",
    "            # Create a pipeline - RF is a stand in, we will populate the classifier part below\n",
    "    pipe_svm = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', SVC())])\n",
    "\n",
    "    search_space_svm = [{'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [.001, .005, .01, .05, .1, .5, 1, 2],\n",
    "                 'classifier__C': [10^(-7), 10^(-6), 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^(1), 10^(2), 10^(3)]},\n",
    "                \n",
    "                {'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['poly'],\n",
    "                 'classifier__degree': [2, 3],\n",
    "                 'classifier__C': [10^(-7), 10^(-6), 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^(1), 10^(2), 10^(3)]},\n",
    "                \n",
    "                {'classifier': [SVC()],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__C': [10^(-7), 10^(-6), 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^(1), 10^(2), 10^(3)]}\n",
    "                ]\n",
    "\n",
    "            # Create grid search \n",
    "    clf_svm = GridSearchCV(pipe_svm, search_space_svm, cv=StratifiedKFold(n_splits=5), \n",
    "                   scoring=['accuracy', 'roc_auc', 'f1_micro'], refit=False,\n",
    "                   verbose=0)\n",
    "\n",
    "            # Fit grid search\n",
    "    best_model_SVM = clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "    h1 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_accuracy']) ]    \n",
    "    h2 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc']) ]\n",
    "    h3 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "    \n",
    "    optimal_hyperparameters_1.append(h1)\n",
    "    optimal_hyperparameters_1.append(h2)\n",
    "    optimal_hyperparameters_1.append(h3)\n",
    "    mean_scores_1.append(best_model_SVM.cv_results_['mean_test_accuracy'][np.argmin(best_model_SVM.cv_results_['rank_test_accuracy'])])\n",
    "    mean_scores_1.append(best_model_SVM.cv_results_['mean_test_roc_auc'][np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc'])])\n",
    "    mean_scores_1.append(best_model_SVM.cv_results_['mean_test_f1_micro'][np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro'])])\n",
    "    \n",
    "    variance_1.append(best_model_SVM.cv_results_['std_test_accuracy'][np.argmin(best_model_SVM.cv_results_['rank_test_accuracy'])])\n",
    "    variance_1.append(best_model_SVM.cv_results_['std_test_roc_auc'][np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc'])])\n",
    "    variance_1.append(best_model_SVM.cv_results_['std_test_f1_micro'][np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro'])])\n",
    "    \n",
    "print(optimal_hyperparameters_1)\n",
    "print(mean_scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "special-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0024166091947189165, 0.001265366198695312, 0.0024166091947189165, 0.002785677655436826, 0.0010084424594746118, 0.002785677655436826, 0.003600000000000003, 0.002033528291918545, 0.003600000000000003, 0.0031240998703626643, 0.0013996168002372866, 0.0031240998703626643, 0.0018547236990991425, 0.0029250948170284675, 0.0018547236990991425]\n"
     ]
    }
   ],
   "source": [
    "print(variance_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-naples",
   "metadata": {},
   "source": [
    "## SVM\n",
    "    letter dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decent-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.5, 'classifier__kernel': 'rbf'}]\n",
      "[0.9574, 0.9915589324101474, 0.9574, 0.9564, 0.9914227406138234, 0.9564, 0.9541999999999999, 0.9906445443568952, 0.9541999999999999, 0.954, 0.9911424653113061, 0.954, 0.9543999999999999, 0.9908261666555502, 0.9543999999999999]\n"
     ]
    }
   ],
   "source": [
    "optimal_hyperparameters_2 = []\n",
    "mean_scores_2 = []\n",
    "\n",
    "for i in range (5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_2, Y_2, train_size = 5000)\n",
    "    \n",
    "    best_model_SVM = clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "    h1 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_accuracy']) ]    \n",
    "    h2 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc']) ]\n",
    "    h3 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "    \n",
    "    optimal_hyperparameters_2.append(h1)\n",
    "    optimal_hyperparameters_2.append(h2)\n",
    "    optimal_hyperparameters_2.append(h3)\n",
    "    mean_scores_2.append(best_model_SVM.cv_results_['mean_test_accuracy'][np.argmin(best_model_SVM.cv_results_['rank_test_accuracy'])])\n",
    "    mean_scores_2.append(best_model_SVM.cv_results_['mean_test_roc_auc'][np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc'])])\n",
    "    mean_scores_2.append(best_model_SVM.cv_results_['mean_test_f1_micro'][np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro'])])\n",
    "print(optimal_hyperparameters_2)\n",
    "print(mean_scores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-malawi",
   "metadata": {},
   "source": [
    "## SVM\n",
    "    Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graduate-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_main = pd.read_csv('adult.data')\n",
    "adult_test = pd.read_csv ('adult.test')\n",
    "adult = pd.concat([adult_main,adult_test], ignore_index = True)\n",
    "#make class column binary\n",
    "adult_ = adult.replace(' >50K', -1)\n",
    "adult = adult_.replace(' <=50K', +1)\n",
    "\n",
    "#move class column to be in 0th index\n",
    "adult = adult[[ ' <=50K','39', ' State-gov', ' 77516', ' Bachelors', ' 13', ' Never-married',\n",
    "       ' Adm-clerical', ' Not-in-family', ' White', ' Male', ' 2174', ' 0',\n",
    "       ' 40', ' United-States', '|1x3 Cross validator']]\n",
    "\n",
    "#rename columns according to data write-up\n",
    "adult = adult.rename(columns={\" <=50K\": \"Y\", '39': 'age', ' State-gov': 'workclass', ' 77516': 'fnlwgt', \n",
    "                              ' Bachelors': 'education', ' 13': 'education-num', ' Never-married': 'marital-status',\n",
    "                              ' Adm-clerical':'occupation', ' Not-in-family' : 'relationship', ' White' : 'race', \n",
    "                              ' Male' : 'sex', ' 2174' : 'capital-gain', ' 0' : 'capital-loss',' 40': 'hours-per-week', \n",
    "                              ' United-States' : 'native-country'})\n",
    "\n",
    "#one hot encode via pd.get_dummies\n",
    "work = pd.get_dummies(adult['workclass']) \n",
    "work.rename(columns = {' ?': 'NA_Work'}, inplace = True)\n",
    "\n",
    "education = pd.get_dummies(adult['education'])\n",
    "marital = pd.get_dummies(adult['marital-status'])\n",
    "occu = pd.get_dummies(adult['occupation']) \n",
    "occu.rename(columns = {' ?': 'NA_Occu'}, inplace = True)\n",
    "\n",
    "relationship = pd.get_dummies(adult['relationship'])\n",
    "race = pd.get_dummies(adult['race'])\n",
    "sex = pd.get_dummies(adult['sex'])\n",
    "country = pd.get_dummies(adult['native-country']) \n",
    "country.rename(columns = {' ?': 'NA_Country'}, inplace = True)\\\n",
    "\n",
    "adult_= pd.concat([work,education,marital,occu,relationship,race,sex,country], axis = 1)\n",
    "\n",
    "#combine the continuous and categorical (now one hot encoded variables)\n",
    "adult_ = pd.concat([adult[['Y', 'age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']],adult_], axis =1)\n",
    "\n",
    "adult_ = adult_[adult_.NA_Work == 0]\n",
    "adult_ = adult_[adult_.NA_Occu == 0]\n",
    "adult_ = adult_[adult_.NA_Country == 0]\n",
    "\n",
    "adult_.drop(['NA_Work','NA_Occu','NA_Country'],axis = 1, inplace=True)\n",
    "\n",
    "adult_.reset_index(inplace = True)\n",
    "adult_.dropna(inplace = True)\n",
    "\n",
    "#split off class data into seperate grouping\n",
    "X_3 = adult_\n",
    "Y_3 = X_3[['Y']]\n",
    "X_3 = X_3.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "diagnostic-antenna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__degree': 3, 'classifier__kernel': 'poly'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__degree': 3, 'classifier__kernel': 'poly'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__degree': 3, 'classifier__kernel': 'poly'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__degree': 3, 'classifier__kernel': 'poly'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__degree': 3, 'classifier__kernel': 'poly'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__kernel': 'linear'}]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "optimal_hyperparameters_3 = []\n",
    "mean_scores_3 = []\n",
    "\n",
    "for i in range (5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_3, Y_3, train_size = 5000)\n",
    "    \n",
    "    best_model_SVM = clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "    h1 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_accuracy']) ]    \n",
    "    h2 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc']) ]\n",
    "    h3 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "    \n",
    "    optimal_hyperparameters_3.append(h1)\n",
    "    optimal_hyperparameters_3.append(h2)\n",
    "    optimal_hyperparameters_3.append(h3)\n",
    "    mean_scores_3.append(best_model_SVM.cv_results_['mean_test_accuracy'][np.argmin(best_model_SVM.cv_results_['rank_test_accuracy'])])\n",
    "    mean_scores_3.append(best_model_SVM.cv_results_['mean_test_roc_auc'][np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc'])])\n",
    "    mean_scores_3.append(best_model_SVM.cv_results_['mean_test_f1_micro'][np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro'])])\n",
    "print(optimal_hyperparameters_3)\n",
    "print(mean_scores_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-majority",
   "metadata": {},
   "source": [
    "## SVM\n",
    "    Cov-type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alien-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data move the class column to the 0th column\n",
    "#rename columns (last 44 columns = leave one out arrangement)\n",
    "cov_type = pd.read_csv('covtype.data')\n",
    "cov_type = cov_type[['5', '2596', '51', '3', '258', '0', '510', '221', '232', '148', '6279', '1',\n",
    "       '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '0.10',\n",
    "       '0.11', '0.12', '0.13', '0.14', '0.15', '0.16', '0.17', '0.18', '0.19',\n",
    "       '0.20', '0.21', '0.22', '0.23', '0.24', '0.25', '0.26', '0.27', '0.28',\n",
    "       '0.29', '0.30', '0.31', '1.1', '0.32', '0.33', '0.34', '0.35', '0.36',\n",
    "       '0.37', '0.38', '0.39', '0.40', '0.41', '0.42']]\n",
    "cov_type.rename(columns = {'5':'Y', '2596':'Elevation', '51': 'Aspect', '3': 'Slope', '258': \n",
    "                           'Horizontal_Distance_To_Hydrology', '0': 'Vertical_Distance_To_Hydrology', '510': \n",
    "                           'Horizontal_Distance_To_Roadways', '221' : 'Hillshade_9am', '232' : 'Hillshade_Noon', \n",
    "                           '148': 'Hillshade_3pm ', '6279': 'Horizontal_Distance_To_Fire_Points'}, inplace = True)\n",
    "\n",
    "#make the classes binary so the largest class (2) is +1, rest is -1\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {1: -1}})\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {3: -1}})\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {4: -1}})\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {5: -1}})\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {6: -1}})\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {7: -1}})\n",
    "cov_type = cov_type.replace(to_replace = {'Y': {2: +1}})\n",
    "\n",
    "X_4 = cov_type\n",
    "Y_4 = X_4[['Y']]\n",
    "X_4 = X_4.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eastern-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 9, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 9, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 8, 'classifier__gamma': 0.05, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.01, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.01, 'classifier__kernel': 'rbf'}, {'classifier': SVC(), 'classifier__C': 11, 'classifier__gamma': 0.01, 'classifier__kernel': 'rbf'}]\n",
      "[0.7896000000000001, 0.854787838721472, 0.7896000000000001, 0.7828, 0.8561640994828764, 0.7828, 0.798, 0.8658867285916727, 0.7980000000000002, 0.7976, 0.8629003681196661, 0.7976, 0.7896000000000001, 0.855717528179633, 0.7896000000000001]\n"
     ]
    }
   ],
   "source": [
    "optimal_hyperparameters_4 = []\n",
    "mean_scores_4 = []\n",
    "\n",
    "for i in range (5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_4, Y_4, train_size = 5000)\n",
    "    \n",
    "    best_model_SVM = clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "    h1 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_accuracy']) ]    \n",
    "    h2 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc']) ]\n",
    "    h3 = best_model_SVM.cv_results_['params'][ np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "    \n",
    "    optimal_hyperparameters_4.append(h1)\n",
    "    optimal_hyperparameters_4.append(h2)\n",
    "    optimal_hyperparameters_4.append(h3)\n",
    "    mean_scores_4.append(best_model_SVM.cv_results_['mean_test_accuracy'][np.argmin(best_model_SVM.cv_results_['rank_test_accuracy'])])\n",
    "    mean_scores_4.append(best_model_SVM.cv_results_['mean_test_roc_auc'][np.argmin(best_model_SVM.cv_results_['rank_test_roc_auc'])])\n",
    "    mean_scores_4.append(best_model_SVM.cv_results_['mean_test_f1_micro'][np.argmin(best_model_SVM.cv_results_['rank_test_f1_micro'])])\n",
    "print(optimal_hyperparameters_4)\n",
    "print(mean_scores_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latin-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9917999999999999, 0.9973695290886383, 0.9917999999999999, 0.9926, 0.9965276692459965, 0.9926, 0.9938, 0.99797560483662, 0.9938, 0.9936, 0.9982742930603237, 0.9936, 0.9914, 0.9971614845611112, 0.9914]\n",
      "[0.9574, 0.9915589324101474, 0.9574, 0.9564, 0.9914227406138234, 0.9564, 0.9541999999999999, 0.9906445443568952, 0.9541999999999999, 0.954, 0.9911424653113061, 0.954, 0.9543999999999999, 0.9908261666555502, 0.9543999999999999]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.7896000000000001, 0.854787838721472, 0.7896000000000001, 0.7828, 0.8561640994828764, 0.7828, 0.798, 0.8658867285916727, 0.7980000000000002, 0.7976, 0.8629003681196661, 0.7976, 0.7896000000000001, 0.855717528179633, 0.7896000000000001]\n"
     ]
    }
   ],
   "source": [
    "print(mean_scores_1)\n",
    "print(mean_scores_2)\n",
    "print(mean_scores_3)\n",
    "print(mean_scores_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-programming",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
